import streamlit as st
import os
from markitdown import MarkItDown
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
from PIL import Image # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë„êµ¬

# 1. ì´ˆê¸° ì„¤ì •
load_dotenv()
md = MarkItDown()

st.set_page_config(page_title="Gemini ë©€í‹°ëª¨ë‹¬ ë¹„ì„œ", layout="wide")
st.title("ğŸ–¼ï¸ ë¬¸ì„œ & ì´ë¯¸ì§€ í†µí•© ë¶„ì„ AI")

# 2. ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    google_api_key = st.text_input("Gemini API Key ì…ë ¥", type="password")
    # ì´ë¯¸ì§€ íŒŒì¼ í˜•ì‹(png, jpg, jpeg) ì¶”ê°€
    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=['pdf', 'xlsx', 'docx', 'txt', 'png', 'jpg', 'jpeg'])

if uploaded_file and google_api_key:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    try:
        # íŒŒì¼ íƒ€ì… í™•ì¸
        file_ext = os.path.splitext(temp_path)[1].lower()
        
        # ì´ë¯¸ì§€ íŒŒì¼ì¼ ê²½ìš° í™”ë©´ì— í‘œì‹œ
        if file_ext in ['.png', '.jpg', '.jpeg']:
            image = Image.open(temp_path)
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
            content = "ì´ê²ƒì€ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ ë‚´ì˜ ê¸€ìì™€ ì‹œê°ì  ìš”ì†Œë¥¼ ë¶„ì„í•´ ì£¼ì„¸ìš”."
        else:
            # ë¬¸ì„œ íŒŒì¼ì¼ ê²½ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ
            with st.status("íŒŒì¼ ì½ëŠ” ì¤‘..."):
                result = md.convert(temp_path)
                content = result.text_content
            with st.expander("ğŸ“„ ì¶”ì¶œëœ ë‚´ìš© í™•ì¸"):
                st.text_area("ë³¸ë¬¸", content, height=200)

        # 3. ì§ˆë¬¸ ë° ë‹µë³€ ì˜ì—­
        st.subheader("ğŸ’¬ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")
        user_question = st.text_input("ì§ˆë¬¸ ì…ë ¥:")

        if user_question:
            with st.spinner("Geminiê°€ ë¶„ì„ ì¤‘..."):
                llm = ChatGoogleGenerativeAI(
                    model="gemini-3-flash-preview", # ì´ë¯¸ì§€ ë¶„ì„ì— íƒì›”í•œ ëª¨ë¸
                    google_api_key=google_api_key
                )
                
                # ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ëŠ” ë°©ì‹ (ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸)
                if file_ext in ['.png', '.jpg', '.jpeg']:
                    # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš° ë©”ì‹œì§€ êµ¬ì„±
                    from langchain_core.messages import HumanMessage
                    message = HumanMessage(
                        content=[
                            {"type": "text", "text": user_question},
                            {"type": "image_url", "image_url": temp_path}
                        ]
                    )
                    response = llm.invoke([message])
                else:
                    # ë¬¸ì„œ íŒŒì¼ì¸ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
                    full_prompt = f"ë¬¸ì„œ ë‚´ìš©: {content}\n\nì§ˆë¬¸: {user_question}\në‹µë³€ ì‹œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì–¸ê¸‰ì´ ìˆë‹¤ë©´ ìƒì„¸íˆ ì„¤ëª…í•´ì¤˜."
                    response = llm.invoke(full_prompt)
                
                # ê²°ê³¼ ì¶œë ¥ (í…ìŠ¤íŠ¸ë§Œ ê¹”ë”í•˜ê²Œ)
                final_answer = response.content if hasattr(response, 'content') else str(response)
                st.write("---")
                st.markdown("### ğŸ“¢ AI ë‹µë³€")
                st.info(final_answer)

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)