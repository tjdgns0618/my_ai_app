import streamlit as st
import os
from markitdown import MarkItDown
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv

# 1. ì´ˆê¸° ì„¤ì •
load_dotenv()
md = MarkItDown()

st.set_page_config(page_title="Gemini ë¬¸ì„œ ë¹„ì„œ", layout="wide")

# UI ë””ìì¸
st.title("ğŸ¤– Gemini íŒŒì¼ ë¶„ì„ ë¹„ì„œ")
st.markdown("""
ì´ ì•±ì€ **PDF, Excel, Word, TXT** íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì¤ë‹ˆë‹¤. 
[Google AI Studio](https://aistudio.google.com/)ì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
""")

# 2. ì‚¬ì´ë“œë°” ì„¤ì • (API í‚¤ ë° íŒŒì¼ ì—…ë¡œë“œ)
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    google_api_key = st.text_input("Gemini API Key ì…ë ¥", type="password")
    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=['pdf', 'xlsx', 'docx', 'txt'])
    
    st.divider()
    st.info("Tip: HWP íŒŒì¼ì€ PDFë¡œ ì €ì¥í•´ì„œ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# 3. ë©”ì¸ ë¡œì§
if uploaded_file and google_api_key:
    # íŒŒì¼ì„ ì„ì‹œë¡œ ë¡œì»¬ì— ì €ì¥
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    try:
        # íŒŒì¼ ë‚´ìš© ì¶”ì¶œ (MarkItDown í™œìš©)
        with st.status("íŒŒì¼ ì½ëŠ” ì¤‘...", expanded=True) as status:
            result = md.convert(temp_path)
            content = result.text_content
            status.update(label="íŒŒì¼ ë³€í™˜ ì™„ë£Œ!", state="complete", expanded=False)

        # ì¶”ì¶œëœ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš© í™•ì¸"):
            st.text_area("íŒŒì¼ ë³¸ë¬¸", content, height=250)

        # 4. ì§ˆë¬¸ ë° ë‹µë³€ ì˜ì—­
        st.subheader("ğŸ’¬ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”")
        user_question = st.text_input("ì˜ˆì‹œ: ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜.")

        if user_question:
            with st.spinner("Geminiê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                # Gemini ëª¨ë¸ ì„¤ì •
                llm = ChatGoogleGenerativeAI(
                    model="gemini-3-flash-preview", 
                    google_api_key=google_api_key,
                    temperature=0.1 # ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
                )
                
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë¬¸ì„œ ë‚´ìš© ì£¼ì…)
                full_prompt = f"""
                ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•˜ì„¸ìš”.
                ë‚´ìš©ì´ ë¬¸ì„œì— ì—†ë‹¤ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”.

                [ë¬¸ì„œ ë‚´ìš©]
                {content}

                [ì‚¬ìš©ì ì§ˆë¬¸]
                {user_question}
                """
                
                response = llm.invoke(full_prompt)
                
                # ë‹µë³€ ë‚´ìš©ë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                if hasattr(response, 'content'):
                    final_answer = response.content
                else:
                    final_answer = str(response)

                # ê²°ê³¼ ì¶œë ¥
                st.write("---")
                st.markdown("### ğŸ“¢ AI ë‹µë³€")

                # ë§Œì•½ ì¶œë ¥ê°’ì´ ì—¬ì „íˆ [{'type': 'text', ...}] í˜•íƒœë¼ë©´ í…ìŠ¤íŠ¸ë§Œ ê³¨ë¼ëƒ„
                if isinstance(final_answer, list) and len(final_answer) > 0:
                    if isinstance(final_answer[0], dict) and 'text' in final_answer[0]:
                        final_answer = final_answer[0]['text']

                st.success(final_answer)

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    finally:
        # ì‘ì—…ì´ ëë‚˜ë©´ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_path):
            os.remove(temp_path)
else:
    if not google_api_key:
        st.warning("ì‚¬ì´ë“œë°”ì— Gemini API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not uploaded_file:
        st.info("ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")